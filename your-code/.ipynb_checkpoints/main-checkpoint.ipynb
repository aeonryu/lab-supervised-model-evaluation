{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lin_reg.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6252054206054058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    " \n",
    "score_test = r2_score(y_test, predictions) \n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.737855710765192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "score_test2 = mean_squared_error(y_test, predictions) \n",
    "print(score_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.235298248700048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "score_test3 = mean_absolute_error(y_test, predictions) \n",
    "print(score_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiroryu/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/shiroryu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "model = log_reg.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_test, prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "score2 = balanced_accuracy_score(y_test, prediction)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-39f44e38e065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1315\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, prediction)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ed95de10d8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1790\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1315\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, prediction)\n",
    "\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-920e4de1f535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1315\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "f1_score = f1_score(y_test, prediction)\n",
    "\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0  9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "conf_m=confusion_matrix(y_test, prediction)\n",
    "\n",
    "print (conf_m)\n",
    "sns.heatmap(conf_m, annot=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
